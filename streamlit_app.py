import streamlit as st
# å¯¼å…¥æ›´æ–°åçš„åç«¯å‡½æ•°
from veriexcite import (
    extract_text_from_pdf,
    extract_bibliography_section,
    split_references,
    search_title,
    find_replacement_reference,
    set_google_api_key,
    ReferenceStatus,
    ReferenceCheckResult,
    ReferenceExtraction,
)
import io
import pandas as pd
import os
from typing import List

# ä½¿ç”¨ veriexcite.py ä¸­çš„ PDF æ–‡æœ¬æå–åŠŸèƒ½
def extract_text_from_uploaded_file(pdf_file: st.runtime.uploaded_file_manager.UploadedFile) -> str:
    """ä½¿ç”¨åç«¯çš„ PyPDF2 æ¨¡å—ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–æ–‡æœ¬ã€‚"""
    if not pdf_file.name.lower().endswith(".pdf"):
        raise ValueError("ä¸Šä¼ çš„æ–‡ä»¶ä¸æ˜¯ PDF æ ¼å¼ã€‚")

    pdf_bytes = pdf_file.getvalue()
    
    # ä¸ºäº†è®© PyPDF2 èƒ½å¤Ÿå¤„ç†ï¼Œéœ€è¦å…ˆå°†å­—èŠ‚æµå†™å…¥ä¸€ä¸ªä¸´æ—¶æ–‡ä»¶
    import tempfile
    temp_dir = tempfile.gettempdir()
    if not os.path.exists(temp_dir):
        os.makedirs(temp_dir)
        
    temp_pdf_path = os.path.join(temp_dir, pdf_file.name)
    
    with open(temp_pdf_path, "wb") as f:
        f.write(pdf_bytes)
        
    # è°ƒç”¨ veriexcite.py ä¸­åŸºäº PyPDF2 çš„å‡½æ•°
    return extract_text_from_pdf(temp_pdf_path)


def display_replacement_suggestions_for_file(results_df: pd.DataFrame, file_name: str):
    """Display replacement suggestions for a specific file in the main page"""
    # Filter for references that need replacement (both invalid and not found)
    warning_refs = results_df[results_df['çŠ¶æ€'].isin(['æœªæ‰¾åˆ°', 'æ— æ•ˆ'])]
    
    if len(warning_refs) > 0:
        st.subheader(f"ğŸ“‹ {file_name} - æ›¿æ¢å»ºè®®")
        
        # Show summary
        st.info(f"å‘ç° {len(warning_refs)} ä¸ªéœ€è¦æ›¿æ¢çš„å‚è€ƒæ–‡çŒ®")
        
        for idx, (_, ref) in enumerate(warning_refs.iterrows()):
            with st.expander(f"ğŸ” å»ºè®® {idx + 1}: {ref['æ ‡é¢˜'][:60]}...", expanded=False):
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.write(f"**ğŸ“„ åŸå§‹æ–‡çŒ®:**")
                    st.write(ref['åŸå§‹æ–‡æœ¬'])
                    st.write(f"**âŒ é—®é¢˜:** {ref['è¯´æ˜']}")
                
                with col2:
                    st.write(f"**ğŸ‘¤ ä½œè€…:** {ref['ä½œè€…']}")
                    st.write(f"**ğŸ“… å¹´ä»½:** {ref['å¹´ä»½']}")
                    if ref['é“¾æ¥']:
                        st.write(f"**ğŸ”— é“¾æ¥:** {ref['é“¾æ¥']}")
                
                st.markdown("---")
                
                if ref['æ›¿æ¢å»ºè®®'] and ref['æ›¿æ¢å»ºè®®'] != "æœªæ‰¾åˆ°åˆé€‚çš„æ›¿æ¢å»ºè®®":
                    st.write("**ğŸ’¡ æ›¿æ¢å»ºè®®:**")
                    
                    # Parse and display suggestions nicely
                    suggestions_text = ref['æ›¿æ¢å»ºè®®']
                    if "ä¸ªæ›¿æ¢å»ºè®®" in suggestions_text:
                        # Split by suggestions
                        parts = suggestions_text.split("å»ºè®® ")
                        if len(parts) > 1:
                            # Extract reasoning
                            reasoning_part = parts[0]
                            reasoning = reasoning_part.split("æ¨èç†ç”±: ")[-1] if "æ¨èç†ç”±: " in reasoning_part else "åŸºäºä¸»é¢˜åˆ†ææœç´¢ä¸‰ä¸ªå­¦æœ¯æ•°æ®åº“"
                            st.write(f"**æ¨èç†ç”±:** {reasoning}")
                            
                            # Display each suggestion
                            for i, part in enumerate(parts[1:], 1):
                                if "åŒ¹é…åº¦:" in part and "æ–‡çŒ®:" in part:
                                    lines = part.strip().split('\n')
                                    if len(lines) >= 3:
                                        # Extract source and score from first line
                                        first_line = lines[0]
                                        if " - " in first_line and "åŒ¹é…åº¦:" in first_line:
                                            source = first_line.split(" - ")[1].split(" (åŒ¹é…åº¦:")[0]
                                            score = first_line.split("åŒ¹é…åº¦: ")[1].split("/100")[0]
                                            
                                            st.write(f"**å»ºè®® {i} - {source}:**")
                                            st.write(f"ğŸ“„ {lines[1].replace('æ–‡çŒ®: ', '')}")
                                            st.write(f"ğŸ”— {lines[2].replace('é“¾æ¥: ', '')}")
                                            st.write(f"â­ åŒ¹é…åº¦: {score}/100")
                                            st.markdown("---")
                    else:
                        st.write(suggestions_text)
                else:
                    st.write("**æ›¿æ¢å»ºè®®:** æš‚æ— åˆé€‚å»ºè®®")
    else:
        st.success(f"âœ… {file_name} - æ‰€æœ‰å‚è€ƒæ–‡çŒ®éªŒè¯é€šè¿‡ï¼Œæ— éœ€æ›¿æ¢å»ºè®®")

def process_and_verify(bib_text: str) -> pd.DataFrame:
    """ä½¿ç”¨æ–°çš„æ™ºèƒ½åç«¯æ¥æå–ã€è§£æå¹¶æ ¡éªŒå‚è€ƒæ–‡çŒ®ã€‚"""
    progress_text = st.empty()
    placeholder = st.empty()
    progress_text.text("æ­£åœ¨ä»å‚è€ƒæ–‡çŒ®æ–‡æœ¬ä¸­è§£ææ¡ç›®...")

    try:
        references: List[ReferenceExtraction] = split_references(bib_text)
    except Exception as e:
        st.error(f"è§£æå‚è€ƒæ–‡çŒ®å¤±è´¥ï¼š{e}")
        return pd.DataFrame()

    status_emoji = {
        "validated": "å·²éªŒè¯",
        "invalid": "æ— æ•ˆ",
        "not_found": "æœªæ‰¾åˆ°",
    }

    results = [
        {
            "ä½œè€…": ref.author,
            "å¹´ä»½": str(ref.year),
            "æ ‡é¢˜": ref.title,
            "åŸå§‹æ–‡æœ¬": ref.bib,
            "çŠ¶æ€": "éªŒè¯ä¸­...",
            "è¯´æ˜": "å¾…å¤„ç†",
            "é“¾æ¥": "",
            "æ›¿æ¢å»ºè®®": "",
        }
        for ref in references
    ]
    df = pd.DataFrame(results)

    column_config = {
        "ä½œè€…": st.column_config.TextColumn("ç¬¬ä¸€ä½œè€…", help="ç¬¬ä¸€ä½œè€…çš„å§“æ°æˆ–æœºæ„åç§°ã€‚"),
        "å¹´ä»½": st.column_config.TextColumn(" å¹´ä»½", width="small"),
        "é“¾æ¥": st.column_config.LinkColumn("é“¾æ¥", display_text="æŸ¥çœ‹"),
        "åŸå§‹æ–‡æœ¬": st.column_config.TextColumn(
            "ğŸ“„ åŸå§‹å‚è€ƒæ–‡çŒ®",
            help="é¼ æ ‡æ‚¬åœå¯æŸ¥çœ‹å®Œæ•´çš„å‚è€ƒæ–‡çŒ®æ–‡æœ¬ã€‚",
            width="medium",
        ),
        "çŠ¶æ€": st.column_config.TextColumn("çŠ¶æ€", help="å‚è€ƒæ–‡çŒ®çš„æ ¡éªŒçŠ¶æ€ã€‚"),
        "è¯´æ˜": st.column_config.TextColumn("è¯´æ˜", help="å…³äºæ ¡éªŒçŠ¶æ€çš„è¯´æ˜ã€‚"),
        "æ›¿æ¢å»ºè®®": st.column_config.TextColumn("æ›¿æ¢å»ºè®®", help="ä¸ºæ— æ³•éªŒè¯çš„å‚è€ƒæ–‡çŒ®æä¾›çš„æ›¿æ¢å»ºè®®ã€‚"),
    }

    df_display = df[['ä½œè€…', 'å¹´ä»½', 'æ ‡é¢˜', 'åŸå§‹æ–‡æœ¬', 'çŠ¶æ€', 'è¯´æ˜', 'é“¾æ¥', 'æ›¿æ¢å»ºè®®']]
    placeholder.dataframe(df_display, use_container_width=True, column_config=column_config)

    verified_count = 0
    warning_count = 0
    total_refs = len(references)

    for index, ref_object in enumerate(references):
        progress_text.text(f"æ­£åœ¨éªŒè¯ {index + 1}/{total_refs} | å·²éªŒè¯: {verified_count} | æœªæ‰¾åˆ°: {warning_count}")
        
        try:
            result: ReferenceCheckResult = search_title(ref_object)
            if result is None:
                result = ReferenceCheckResult(status=ReferenceStatus.NOT_FOUND, explanation="Search returned no result.")
        except Exception as e:
            st.error(f"Error processing reference: {e}")
            result = ReferenceCheckResult(status=ReferenceStatus.NOT_FOUND, explanation=f"Processing error: {e}")

        df.loc[index, "çŠ¶æ€"] = status_emoji.get(result.status.value)
        df.loc[index, "è¯´æ˜"] = result.explanation
        df.loc[index, "é“¾æ¥"] = ref_object.URL if hasattr(ref_object, 'URL') else ""

        if result.status == ReferenceStatus.VALIDATED:
            verified_count += 1
        else:
            warning_count += 1
            # Show progress for replacement suggestions
            progress_container = st.empty()
            progress_text = progress_container.text(f"æ­£åœ¨ä¸º '{ref_object.title}' å¯»æ‰¾æ›¿æ¢å»ºè®®...")
            
            def update_progress(message):
                progress_text.text(message)
            
            suggestion = find_replacement_reference(ref_object, progress_callback=update_progress)
            
            # Clear progress text
            progress_container.empty()
            
            if suggestion.found:
                # Format three suggestions nicely for CSV export
                suggestion_count = sum([1 for s in [suggestion.suggestion1_bib, suggestion.suggestion2_bib, suggestion.suggestion3_bib] if s.strip()])
                suggestion_text = f"æ‰¾åˆ° {suggestion_count} ä¸ªæ›¿æ¢å»ºè®®\n"
                suggestion_text += f"æ¨èç†ç”±: {suggestion.reasoning}\n\n"
                
                # Add arXiv suggestion
                if suggestion.suggestion1_bib and suggestion.suggestion1_bib.strip():
                    suggestion_text += f"å»ºè®® 1 - {suggestion.suggestion1_source} (åŒ¹é…åº¦: {suggestion.suggestion1_score}/100):\n"
                    suggestion_text += f"æ–‡çŒ®: {suggestion.suggestion1_bib}\n"
                    suggestion_text += f"é“¾æ¥: {suggestion.suggestion1_url}\n\n"
                
                # Add Crossref suggestion
                if suggestion.suggestion2_bib and suggestion.suggestion2_bib.strip():
                    suggestion_text += f"å»ºè®® 2 - {suggestion.suggestion2_source} (åŒ¹é…åº¦: {suggestion.suggestion2_score}/100):\n"
                    suggestion_text += f"æ–‡çŒ®: {suggestion.suggestion2_bib}\n"
                    suggestion_text += f"é“¾æ¥: {suggestion.suggestion2_url}\n\n"
                
                # Add Google Scholar suggestion
                if suggestion.suggestion3_bib and suggestion.suggestion3_bib.strip():
                    suggestion_text += f"å»ºè®® 3 - {suggestion.suggestion3_source} (åŒ¹é…åº¦: {suggestion.suggestion3_score}/100):\n"
                    suggestion_text += f"æ–‡çŒ®: {suggestion.suggestion3_bib}\n"
                    suggestion_text += f"é“¾æ¥: {suggestion.suggestion3_url}\n\n"
                
                df.loc[index, "æ›¿æ¢å»ºè®®"] = suggestion_text
            else:
                df.loc[index, "æ›¿æ¢å»ºè®®"] = f"æœªæ‰¾åˆ°åˆé€‚çš„æ›¿æ¢å»ºè®®\nåŸå› : {suggestion.reasoning}"
    
    progress_text.text(f"å¤„ç†å®Œæˆï¼ | å·²éªŒè¯: {verified_count} | éœ€è¦æ›¿æ¢: {warning_count}")
    
    # Clear the progress text and placeholder after completion
    progress_text.empty()
    placeholder.empty()

    return df


def main():
    st.set_page_config(
        page_title="å­¦ä½‘æ˜Ÿé€”: å‚è€ƒæ–‡çŒ®æ ¸éªŒå·¥å…·",
        page_icon="ğŸ”",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # Header with better styling
    st.markdown("""
    <div style="text-align: center; padding: 2rem 0; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin-bottom: 2rem;">
        <h1 style="color: white; margin: 0; font-size: 2.5rem;">è®ºæ–‡æ£€æŸ¥å·¥å…·</h1>
        <p style="color: white; margin: 0.5rem 0 0 0; font-size: 1.2rem;">æ™ºèƒ½å‚è€ƒæ–‡çŒ®æ ¸éªŒä¸æ›¿æ¢å»ºè®®å·¥å…·</p>
    </div>
    """, unsafe_allow_html=True)

    with st.sidebar:
        st.markdown("""
        <div style="background-color: #e3f2fd; padding: 1rem; border-radius: 10px; margin-bottom: 1rem;">
            <h3 style="margin-top: 0; color: #1976d2;">åŠŸèƒ½ç‰¹ç‚¹</h3>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="background-color: #f8f9fa; padding: 1rem; border-radius: 10px; margin-bottom: 1rem;">
            <ul style="margin: 0; padding-left: 1.2rem;">
                <li><strong>æ™ºèƒ½è§£æ</strong>ï¼šè‡ªåŠ¨æå–PDFä¸­çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨</li>
                <li><strong>å¤šæºéªŒè¯</strong>ï¼šé€šè¿‡Crossrefã€arXivã€Google Scholarç­‰éªŒè¯æ–‡çŒ®çœŸå®æ€§</li>
                <li><strong>æ™ºèƒ½æ›¿æ¢</strong>ï¼šAIåˆ†æä¸»é¢˜åä»ä¸‰ä¸ªæ•°æ®åº“æä¾›æ›¿æ¢å»ºè®®</li>
                <li><strong>å¤šè¯­è¨€æ”¯æŒ</strong>ï¼šæ”¯æŒä¸­ã€è‹±ã€æ—¥ã€æ³•ã€å¾·ã€è¥¿ã€ä¿„ã€æ„ã€è‘¡ã€éŸ©ç­‰8+è¯­è¨€</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

        st.markdown("---")
        
        
        pdf_files = st.file_uploader(
            "ä¸Šä¼ PDFæ–‡ä»¶", 
            type="pdf", 
            accept_multiple_files=True,
            help="æ”¯æŒä¸Šä¼ å¤šä¸ªPDFæ–‡ä»¶è¿›è¡Œæ‰¹é‡å¤„ç†"
        )

        st.markdown("---")
        
        st.markdown("""
        <div style="background-color: #fff3e0; padding: 1rem; border-radius: 10px; margin: 1rem 0;">
            <h4 style="margin-top: 0; color: #f57c00;">APIå¯†é’¥</h4>
            <p style="margin-bottom: 0; font-size: 0.9rem;">éœ€è¦Google Gemini APIå¯†é’¥æ¥ç”Ÿæˆæ›¿æ¢å»ºè®®</p>
        </div>
        """, unsafe_allow_html=True)
        
        api_key = st.text_input(
            "Google Gemini API å¯†é’¥:", 
            type="password",
            help="åœ¨ [Google AI Studio](https://ai.google.dev/) å…è´¹ç”³è¯·"
        )
        
        if api_key:
            st.success("APIå¯†é’¥å·²è®¾ç½®")
        else:
            st.warning("è¯·è®¾ç½®APIå¯†é’¥ä»¥è·å–æ›¿æ¢å»ºè®®")

        st.markdown("---")
        
        # Status indicator
        if st.session_state.get('verification_completed', False):
            st.success("âœ… éªŒè¯å·²å®Œæˆ")
        elif st.session_state.get('start_verification', False):
            st.success("âœ… éªŒè¯è¿›è¡Œä¸­...")
        else:
            st.info("â³ ç­‰å¾…å¼€å§‹éªŒè¯")
        
        st.markdown("---")
        
        # Start verification button
        if st.button("ğŸš€ å¼€å§‹éªŒè¯", type="primary", use_container_width=True):
            st.session_state.start_verification = True
            st.rerun()
        
        # Reset button
        if st.button("ğŸ”„ é‡æ–°å¼€å§‹", use_container_width=True):
            st.session_state.start_verification = False
            st.session_state.verification_completed = False
            if 'all_results' in st.session_state:
                del st.session_state.all_results
            st.rerun()

    # Main processing area
    if pdf_files and api_key:
        if not st.session_state.get('start_verification', False):
            st.info("ğŸ‘† è¯·ç‚¹å‡»ä¾§è¾¹æ çš„ 'ğŸš€ å¼€å§‹éªŒè¯' æŒ‰é’®å¼€å§‹å¤„ç†")
        elif st.session_state.get('start_verification', False) and not st.session_state.get('verification_completed', False):
            try:
                set_google_api_key(api_key)
                all_results = []

                for pdf_file in pdf_files:
                    st.subheader(f"æ­£åœ¨å¤„ç†: {pdf_file.name}")
                    pdf_content = extract_text_from_uploaded_file(pdf_file)
                    bib_text = extract_bibliography_section(pdf_content)

                    with st.expander(f"ä» {pdf_file.name} æå–çš„å‚è€ƒæ–‡çŒ®æ–‡æœ¬"):
                        st.text_area("æå–å†…å®¹", bib_text, height=200, label_visibility="hidden")

                    results_df = process_and_verify(bib_text)
                    if not results_df.empty:
                        results_df['æ¥æºæ–‡ä»¶'] = pdf_file.name
                        all_results.append(results_df)
                        
                        # Display replacement suggestions for this file
                        display_replacement_suggestions_for_file(results_df, pdf_file.name)
                        
                    st.success(f"å·²å®Œæˆ: {pdf_file.name}")
                    st.markdown("---")

                if all_results:
                    # Store results in session state for persistence
                    st.session_state.all_results = all_results
                    st.session_state.verification_completed = True
                    
                    # Show completion message
                    st.success("ğŸ‰ æ‰€æœ‰æ–‡ä»¶éªŒè¯å®Œæˆï¼")

            except ValueError as ve:
                st.error(str(ve))
            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
        
        # Show results if verification is completed
        if st.session_state.get('verification_completed', False) and 'all_results' in st.session_state:
            all_results = st.session_state.all_results
            combined_results = pd.concat(all_results, ignore_index=True)
            
            # Display all three replacement suggestions in the CSV
            st.subheader("åˆ†æç»“æœ")
            
            # Show summary statistics
            total_refs = len(combined_results)
            verified_refs = len(combined_results[combined_results['çŠ¶æ€'] == 'å·²éªŒè¯'])
            invalid_refs = len(combined_results[combined_results['çŠ¶æ€'] == 'æ— æ•ˆ'])
            not_found_refs = len(combined_results[combined_results['çŠ¶æ€'] == 'æœªæ‰¾åˆ°'])
            warning_refs = invalid_refs + not_found_refs
            success_rate = (verified_refs / total_refs * 100) if total_refs > 0 else 0
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æ€»å‚è€ƒæ–‡çŒ®", total_refs)
            with col2:
                st.metric("å·²éªŒè¯", verified_refs)
            with col3:
                st.metric("éœ€è¦æ›¿æ¢", warning_refs)
            with col4:
                st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")
            
            st.markdown("---")
            
            # Show the results table with better formatting
            st.dataframe(
                combined_results, 
                use_container_width=True,
                column_config={
                    "ä½œè€…": st.column_config.TextColumn("ç¬¬ä¸€ä½œè€…"),
                    "å¹´ä»½": st.column_config.TextColumn("å¹´ä»½", width="small"),
                    "æ ‡é¢˜": st.column_config.TextColumn("æ ‡é¢˜", width="medium"),
                    "åŸå§‹æ–‡æœ¬": st.column_config.TextColumn("åŸå§‹å‚è€ƒæ–‡çŒ®", width="large"),
                    "çŠ¶æ€": st.column_config.TextColumn("çŠ¶æ€"),
                    "è¯´æ˜": st.column_config.TextColumn("è¯´æ˜", width="medium"),
                    "é“¾æ¥": st.column_config.LinkColumn("é“¾æ¥", display_text="æŸ¥çœ‹"),
                    "æ›¿æ¢å»ºè®®": st.column_config.TextColumn("æ›¿æ¢å»ºè®®", width="large"),
                    "æ¥æºæ–‡ä»¶": st.column_config.TextColumn("æ¥æºæ–‡ä»¶")
                }
            )
            
            # Download button
            csv = combined_results.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
            st.download_button(
                label="ä¸‹è½½æ‰€æœ‰ç»“æœ (CSV)",
                data=csv,
                file_name='åˆ†æç»“æœ.csv',
                mime='text/csv',
                type="primary"
            )
    elif pdf_files and not api_key:
        st.warning("è¯·è®¾ç½®APIå¯†é’¥ä»¥å¼€å§‹å¤„ç†")
    elif not pdf_files:
        st.info("è¯·ä¸Šä¼ PDFæ–‡ä»¶å¹¶è®¾ç½®APIå¯†é’¥ä»¥å¼€å§‹å¤„ç†")


if __name__ == "__main__":
    main()