import streamlit as st
# å¯¼å…¥æ›´æ–°åçš„åç«¯å‡½æ•°
from veriexcite import (
    extract_text_from_pdf,
    extract_bibliography_section,
    split_references,
    verify_reference_with_search,
    find_replacement_reference,
    set_google_api_key,
    ReferenceStatus,
    VerificationResult,
    ReferenceExtraction,
)
import io
import pandas as pd
import os

# ä½¿ç”¨ veriexcite.py ä¸­æ›´å¼ºå¤§çš„ PDF æ–‡æœ¬æå–åŠŸèƒ½
def extract_text_from_uploaded_file(pdf_file: st.runtime.uploaded_file_manager.UploadedFile) -> str:
    """ä½¿ç”¨åç«¯çš„ fitz æ¨¡å—ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–æ–‡æœ¬ã€‚"""
    if not pdf_file.name.lower().endswith(".pdf"):
        raise ValueError("ä¸Šä¼ çš„æ–‡ä»¶ä¸æ˜¯ PDF æ ¼å¼ã€‚")

    # è·å–ä¸Šä¼ æ–‡ä»¶çš„å­—èŠ‚æµ
    pdf_bytes = pdf_file.getvalue()
    
    # ä¸ºäº†è®© fitz èƒ½å¤Ÿå¤„ç†ï¼Œéœ€è¦å…ˆå°†å­—èŠ‚æµå†™å…¥ä¸€ä¸ªä¸´æ—¶æ–‡ä»¶
    # Streamlit Cloud ç¯å¢ƒä¸­ï¼Œ/tmp/ æ˜¯ä¸€ä¸ªå¯å†™çš„ä¸´æ—¶ç›®å½•
    temp_dir = "/tmp"
    if not os.path.exists(temp_dir):
        os.makedirs(temp_dir) # å¦‚æœç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»º
        
    temp_pdf_path = os.path.join(temp_dir, pdf_file.name)
    
    with open(temp_pdf_path, "wb") as f:
        f.write(pdf_bytes)
        
    # è°ƒç”¨ veriexcite.py ä¸­åŸºäº PyMuPDF çš„å‡½æ•°
    return extract_text_from_pdf(temp_pdf_path)


def process_and_verify(bib_text: str) -> pd.DataFrame:
    """ä½¿ç”¨æ–°çš„æ™ºèƒ½åç«¯æ¥æå–ã€è§£æå¹¶æ ¡éªŒå‚è€ƒæ–‡çŒ®ã€‚"""
    progress_text = st.empty()
    placeholder = st.empty()
    progress_text.text("æ­£åœ¨ä»å‚è€ƒæ–‡çŒ®æ–‡æœ¬ä¸­è§£ææ¡ç›®...")

    try:
        references: List[ReferenceExtraction] = split_references(bib_text)
    except Exception as e:
        st.error(f"è§£æå‚è€ƒæ–‡çŒ®å¤±è´¥ï¼š{e}")
        return pd.DataFrame()

    status_emoji = {
        "validated": "âœ… å·²éªŒè¯",
        "not_found": "âš ï¸ æœªæ‰¾åˆ°",
    }

    # å‡†å¤‡ç”¨äºæ˜¾ç¤ºçš„ DataFrame ç»“æ„
    results = [
        {
            "ä½œè€…": ref.author,
            "å¹´ä»½": str(ref.year),
            "æ ‡é¢˜": ref.title,
            "åŸå§‹æ–‡æœ¬": ref.bib,
            "çŠ¶æ€": "â³ éªŒè¯ä¸­...",
            "è¯´æ˜": "å¾…å¤„ç†",
            "é“¾æ¥": "",
            "æ›¿æ¢å»ºè®®": "",
        }
        for ref in references
    ]
    df = pd.DataFrame(results)

    column_config = {
        "ä½œè€…": st.column_config.TextColumn("ç¬¬ä¸€ä½œè€…", help="ç¬¬ä¸€ä½œè€…çš„å§“æ°æˆ–æœºæ„åç§°ã€‚"),
        "å¹´ä»½": st.column_config.TextColumn(width="small"),
        "é“¾æ¥": st.column_config.LinkColumn("é“¾æ¥", display_text="ğŸ”—"),
        "åŸå§‹æ–‡æœ¬": st.column_config.TextColumn(
            "åŸå§‹å‚è€ƒæ–‡çŒ®",
            help="é¼ æ ‡æ‚¬åœå¯æŸ¥çœ‹å®Œæ•´çš„å‚è€ƒæ–‡çŒ®æ–‡æœ¬ã€‚",
            width="medium",
        ),
        "çŠ¶æ€": st.column_config.TextColumn(help="å‚è€ƒæ–‡çŒ®çš„æ ¡éªŒçŠ¶æ€ã€‚"),
        "è¯´æ˜": st.column_config.TextColumn(help="å…³äºæ ¡éªŒçŠ¶æ€çš„è¯´æ˜ã€‚"),
        "æ›¿æ¢å»ºè®®": st.column_config.TextColumn(help="ä¸ºæ— æ³•éªŒè¯çš„å‚è€ƒæ–‡çŒ®æä¾›çš„æ›¿æ¢å»ºè®®ã€‚"),
    }

    df_display = df[['ä½œè€…', 'å¹´ä»½', 'æ ‡é¢˜', 'åŸå§‹æ–‡æœ¬', 'çŠ¶æ€', 'è¯´æ˜', 'é“¾æ¥', 'æ›¿æ¢å»ºè®®']]
    placeholder.dataframe(df_display, use_container_width=True, column_config=column_config)

    verified_count = 0
    warning_count = 0
    total_refs = len(references)

    for index, ref_object in enumerate(references):
        progress_text.text(f"æ­£åœ¨éªŒè¯ {index + 1}/{total_refs} | å·²éªŒè¯: {verified_count} | æœªæ‰¾åˆ°: {warning_count}")
        
        # è°ƒç”¨æ–°çš„ã€ç»Ÿä¸€çš„æ™ºèƒ½éªŒè¯å‡½æ•°
        result: VerificationResult = verify_reference_with_search(ref_object)

        df.loc[index, "çŠ¶æ€"] = status_emoji.get(result.status.value)
        df.loc[index, "è¯´æ˜"] = result.explanation
        df.loc[index, "é“¾æ¥"] = result.url

        if result.status == ReferenceStatus.VALIDATED:
            verified_count += 1
        else:
            warning_count += 1
            # å¦‚æœæœªæ‰¾åˆ°ï¼Œåˆ™è·å–æ›¿æ¢å»ºè®®
            suggestion = find_replacement_reference(ref_object)
            df.loc[index, "æ›¿æ¢å»ºè®®"] = suggestion
    
    # æ‰€æœ‰å¤„ç†å®Œæˆåï¼Œæ›´æ–°æœ€ç»ˆçš„ç»Ÿè®¡ä¿¡æ¯å’Œè¡¨æ ¼
    progress_text.text(f"å¤„ç†å®Œæˆï¼ | å·²éªŒè¯: {verified_count} | æœªæ‰¾åˆ°: {warning_count}")
    df_display = df[['ä½œè€…', 'å¹´ä»½', 'æ ‡é¢˜', 'åŸå§‹æ–‡æœ¬', 'çŠ¶æ€', 'è¯´æ˜', 'é“¾æ¥', 'æ›¿æ¢å»ºè®®']]
    placeholder.dataframe(df_display, use_container_width=True, column_config=column_config)

    return df


def main():
    st.set_page_config(
        page_title="VeriExCite: å‚è€ƒæ–‡çŒ®æ ¸éªŒå·¥å…·",
        page_icon="ğŸ”",
        layout="wide",
    )

    st.title("VeriExCite: å‚è€ƒæ–‡çŒ®æ ¸éªŒå·¥å…·")
    st.write(
        "æœ¬å·¥å…·æ—¨åœ¨å¸®åŠ©æ‚¨æ ¸éªŒå­¦æœ¯è®ºæ–‡ï¼ˆPDFæ ¼å¼ï¼‰ä¸­å¼•ç”¨çš„å‚è€ƒæ–‡çŒ®æ˜¯å¦å­˜åœ¨ã€‚å®ƒä¼šè‡ªåŠ¨æå–æ–‡çŒ®åˆ—è¡¨ï¼Œè§£ææ¯ä¸ªæ¡ç›®ï¼Œå¹¶éªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚"
    )

    with st.sidebar:
        st.header("è¾“å…¥")
        pdf_files = st.file_uploader("ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ª PDF æ–‡ä»¶", type="pdf", accept_multiple_files=True)

        st.markdown(
            "æ‚¨å¯ä»¥åœ¨ [Google AI Studio](https://ai.google.dev/) å…è´¹ç”³è¯· Gemini API å¯†é’¥ï¼Œæ¯å¤©äº«æœ‰ 1500 æ¬¡è¯·æ±‚çš„å…è´¹é¢åº¦ã€‚"
        )
        api_key = st.text_input("è¯·è¾“å…¥æ‚¨çš„ Google Gemini API å¯†é’¥:", type="password")

    if st.sidebar.button("å¼€å§‹éªŒè¯"):
        if not pdf_files:
            st.warning("è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ª PDF æ–‡ä»¶ã€‚")
            return

        if not api_key:
            st.warning("è¯·è¾“å…¥æ‚¨çš„ Google Gemini API å¯†é’¥ã€‚")
            return

        try:
            set_google_api_key(api_key)
            all_results = []

            for pdf_file in pdf_files:
                st.subheader(f"æ­£åœ¨å¤„ç†: {pdf_file.name}")
                # ä½¿ç”¨æ–°çš„æ–‡æœ¬æå–å‡½æ•°
                pdf_content = extract_text_from_uploaded_file(pdf_file)
                bib_text = extract_bibliography_section(pdf_content)

                with st.expander(f"ä» {pdf_file.name} æå–çš„å‚è€ƒæ–‡çŒ®æ–‡æœ¬"):
                    st.text_area("æå–å†…å®¹", bib_text, height=200, label_visibility="hidden")

                results_df = process_and_verify(bib_text)
                if not results_df.empty:
                    results_df['æ¥æºæ–‡ä»¶'] = pdf_file.name
                    all_results.append(results_df)
                st.success(f"å·²å®Œæˆ: {pdf_file.name}")

            if all_results:
                combined_results = pd.concat(all_results, ignore_index=True)
                csv = combined_results.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ä¸‹è½½æ‰€æœ‰ç»“æœ (CSV)",
                    data=csv,
                    file_name='VeriExCite_åˆ†æç»“æœ.csv',
                    mime='text/csv',
                )

        except ValueError as ve:
            st.error(str(ve))
        except Exception as e:
            st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")


if __name__ == "__main__":
    main()